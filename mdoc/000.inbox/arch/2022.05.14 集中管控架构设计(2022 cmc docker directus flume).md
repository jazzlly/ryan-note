# 单区系统架构

## 信息采集架构

![[集中管控信息采集架构图.png]]


省集中管控需要管理多个网络区域，上图为单区域信息搜集架构。系统信息源头包括syslog, snmp，http等多种类型。根据数据的类型将数据划分为实体数据和日志数据。实体数据为系统的资产数据，如主机设备，网络设备，移动设备，组织机构，人员，应用等等。这些数据规模在10万以下，保存在传统数据库中。日志数据是被管控系统使用中产生的活动信息，如主机和网络设备的网络活动，移动设备使用应用信息，用户的登录活动等等。这些信息会随着时间不断增长，保存在大数据系统中。

## Flume数据采集架构

![[Flume数据采集架构.png]]

### 信息采集系统特点

1. 实体信息无代码化
对于实体信息，集控系统管理员只需要在directus web界面定义好schema, 上报方即可根据schema上报数据。对于采集系统无任何代码改动。

2. 简单日志信息无代码化
简单日志信息是所有信息都在上报消息体中，不需要系统补全的日志。对于简单实体信息，上报方可直接根据给定schema上报数据。对于采集系统无代码改动。

3. 复杂日志信息无代码化
复杂日志信息只有部分信息在上报消息体中，另外信息需要系统补全。比如移动设备使用应用信息，上报信息中包括了设备uuid和应用包名。需要通过设备uuid找到并补全设备用户使用账号，用户姓名。需要通过应用包名找到应用名称。
对于复制日志信息，也应做到无代码化。通过外部文件配置好补全逻辑，即可实现补全上报逻辑。

## 系统部署架构


# 分布式跨区架构
![[集中管控跨区架构.png]]

## 实体数据跨区流程
实体数据跨区流程主要包括数据入库流程和数据处理流程。

1. 数据入库流程是将各个数据源的数据保存到数据通道。如下图，系统将三个数据源，syslog, http和上一区avro输入保存到了kafka pekall-cmc-entity topic中。单区实体数据处理系统够处理从syslog和http中输入的实体数据。为了处理跨区数据，新增了avro数据源。上一区实体数据通过该数据源传递到本区。

![[png数据入库流程.png]]
2. 数据处理流程是对kafka管道中的数据进行处理，数据处理操作包括数据保存和数据转发。如下图， 系统将kafka topic pekall-cmc-entity中数据保存到了directus中。同时，将数据转发到了下区的avro数据源中。
![[数据处理流程.png]]

3. 对于二区数据，需要一个一区数据avro的输入和三区数据avro输出。

## 日志数据跨区处理
日志数据跨区处理和实体数据跨区处理流程几乎完全一致。区别是使用了不同的kafka topic: pekall-cmc-log, 数据通过定制的sink保存到elasticsearch中。

## 命令跨区处理
命令数据跨区处理和实体数据跨区处理流程几乎完全一致。区别是命令数据方向和日志数据方向是相反的，使用了不同的kafka topic: pekall-cmc-command, 数据通过定制的sink进行命令处理。
